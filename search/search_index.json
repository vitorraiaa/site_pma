{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#template-de-entrega","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"#grupokit-x","title":"Grupo/Kit X","text":"<ol> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> <li>Maria Oliveira</li> <li>Grupo K<ul> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> </ul> </li> </ol> <p>Instru\u00e7\u00f5es</p> <p>Voc\u00eas devem utilizar este template como um bloco de notas para registrar o que foi feito e o que falta fazer. Voc\u00eas devem adicionar as informa\u00e7\u00f5es necess\u00e1rias. O template deve ser editado e atualizado a cada entrega, registrando assim a data de entrega e o que foi feito at\u00e9 o momento via Git.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 23/02/2025</li> <li> Roteiro 2</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"notebook1/ex1_data/","title":"Notebook 1","text":"In\u00a0[14]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nclass0 = {\n    \"x\": np.random.normal(2, 0.8, size=100),\n    \"y\": np.random.normal(3, 2.5, size=100)\n}\n\nclass1 = {\n    \"x\": np.random.normal(5, 1.2, size=100),\n    \"y\": np.random.normal(6, 1.9, size=100)\n}\n\nclass2 = {\n    \"x\": np.random.normal(8, 0.9, size=100),\n    \"y\": np.random.normal(1, 0.9, size=100)\n}\n\nclass3 = {\n    \"x\": np.random.normal(15, 0.5, size=100),\n    \"y\": np.random.normal(4, 2.0, size=100)\n}\n\n\nplt.figure(figsize=(8,6))\nplt.scatter(class0[\"x\"], class0[\"y\"], label=\"Class 0\", alpha=0.6)\nplt.scatter(class1[\"x\"], class1[\"y\"], label=\"Class 1\", alpha=0.6)\nplt.scatter(class2[\"x\"], class2[\"y\"], label=\"Class 2\", alpha=0.6)\nplt.scatter(class3[\"x\"], class3[\"y\"], label=\"Class 3\", alpha=0.6)\nplt.legend()\nplt.xlabel(\"X1\")\nplt.ylabel(\"X2\")\nplt.title(\"Dados Sinteticos Aleat\u00f3rios\")\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt  np.random.seed(42)  class0 = {     \"x\": np.random.normal(2, 0.8, size=100),     \"y\": np.random.normal(3, 2.5, size=100) }  class1 = {     \"x\": np.random.normal(5, 1.2, size=100),     \"y\": np.random.normal(6, 1.9, size=100) }  class2 = {     \"x\": np.random.normal(8, 0.9, size=100),     \"y\": np.random.normal(1, 0.9, size=100) }  class3 = {     \"x\": np.random.normal(15, 0.5, size=100),     \"y\": np.random.normal(4, 2.0, size=100) }   plt.figure(figsize=(8,6)) plt.scatter(class0[\"x\"], class0[\"y\"], label=\"Class 0\", alpha=0.6) plt.scatter(class1[\"x\"], class1[\"y\"], label=\"Class 1\", alpha=0.6) plt.scatter(class2[\"x\"], class2[\"y\"], label=\"Class 2\", alpha=0.6) plt.scatter(class3[\"x\"], class3[\"y\"], label=\"Class 3\", alpha=0.6) plt.legend() plt.xlabel(\"X1\") plt.ylabel(\"X2\") plt.title(\"Dados Sinteticos Aleat\u00f3rios\") plt.show()  <ol> <li><p>Plot the Data: Create a 2D scatter plot showing all the data points. Use a different color for each class to make them distinguishable.</p> </li> <li><p>Analyze and Draw Boundaries:</p> <ol> <li>Examine the scatter plot carefully. Describe the distribution and overlap of the four classes.<ul> <li>Class 0 and 1 have the most overlap, being pretty ditinguishable from the other two classes (numbers 2 and 3). The most segregated one is class 3, being at the far end of the X1 axis of the plot.</li> </ul> </li> <li>Based on your visual inspection, could a simple, linear boundary separate all classes?<ul> <li>I would argue that a line can be made to separate classes from each other, but the line would also put different classes on the same side. This would mean we would need at minimum a second line to properly separate all classes.</li> </ul> </li> <li>On your plot, sketch the decision boundaries that you think a trained neural network might learn to separate these classes.</li> </ol> <p> </p> </li> </ol> In\u00a0[15]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\nnp.random.seed(42)\n\nmu_A = [0, 0, 0, 0, 0]\nSigma_A = np.array([\n    [1.0, 0.8, 0.1, 0.0, 0.0],\n    [0.8, 1.0, 0.3, 0.0, 0.0],\n    [0.1, 0.3, 1.0, 0.5, 0.0],\n    [0.0, 0.0, 0.5, 1.0, 0.2],\n    [0.0, 0.0, 0.0, 0.2, 1.0]\n])\n\nmu_B = [1.5, 1.5, 1.5, 1.5, 1.5]\nSigma_B = np.array([\n    [1.5, -0.7, 0.2, 0.0, 0.0],\n    [-0.7, 1.5, 0.4, 0.0, 0.0],\n    [0.2, 0.4, 1.5, 0.6, 0.0],\n    [0.0, 0.0, 0.6, 1.5, 0.3],\n    [0.0, 0.0, 0.0, 0.3, 1.5]\n])\n\nclass_A = np.random.multivariate_normal(mu_A, Sigma_A, size=500)\nclass_B = np.random.multivariate_normal(mu_B, Sigma_B, size=500)\n\nX = np.vstack((class_A, class_B))\ny = np.array([0]*500 + [1]*500)\n\nprint(\"Dataset shape:\", X.shape)\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X)\n\nplt.figure(figsize=(8,6))\nplt.scatter(X_pca[y==0, 0], X_pca[y==0, 1], alpha=0.6, label=\"Class A\")\nplt.scatter(X_pca[y==1, 0], X_pca[y==1, 1], alpha=0.6, label=\"Class B\")\nplt.title(\"PCA de dados Sint\u00e9ticos 5D - Redu\u00e7\u00e3o para 2D\")\nplt.xlabel(\"PC1\")\nplt.ylabel(\"PC2\")\nplt.legend()\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt from sklearn.decomposition import PCA  np.random.seed(42)  mu_A = [0, 0, 0, 0, 0] Sigma_A = np.array([     [1.0, 0.8, 0.1, 0.0, 0.0],     [0.8, 1.0, 0.3, 0.0, 0.0],     [0.1, 0.3, 1.0, 0.5, 0.0],     [0.0, 0.0, 0.5, 1.0, 0.2],     [0.0, 0.0, 0.0, 0.2, 1.0] ])  mu_B = [1.5, 1.5, 1.5, 1.5, 1.5] Sigma_B = np.array([     [1.5, -0.7, 0.2, 0.0, 0.0],     [-0.7, 1.5, 0.4, 0.0, 0.0],     [0.2, 0.4, 1.5, 0.6, 0.0],     [0.0, 0.0, 0.6, 1.5, 0.3],     [0.0, 0.0, 0.0, 0.3, 1.5] ])  class_A = np.random.multivariate_normal(mu_A, Sigma_A, size=500) class_B = np.random.multivariate_normal(mu_B, Sigma_B, size=500)  X = np.vstack((class_A, class_B)) y = np.array([0]*500 + [1]*500)  print(\"Dataset shape:\", X.shape)  pca = PCA(n_components=2) X_pca = pca.fit_transform(X)  plt.figure(figsize=(8,6)) plt.scatter(X_pca[y==0, 0], X_pca[y==0, 1], alpha=0.6, label=\"Class A\") plt.scatter(X_pca[y==1, 0], X_pca[y==1, 1], alpha=0.6, label=\"Class B\") plt.title(\"PCA de dados Sint\u00e9ticos 5D - Redu\u00e7\u00e3o para 2D\") plt.xlabel(\"PC1\") plt.ylabel(\"PC2\") plt.legend() plt.show()  <pre>Dataset shape: (1000, 5)\n</pre> <ol> <li>Visualize the Data: Since you cannot directly plot a 5D graph, you must reduce its dimensionality.<ul> <li>Use a technique like Principal Component Analysis (PCA) to project the 5D data down to 2 dimensions.</li> <li>Create a scatter plot of this 2D representation, coloring the points by their class (A or B).</li> </ul> </li> <li>Analyze the Plots:<ol> <li><p>Based on your 2D projection, describe the relationship between the two classes.</p> <ul> <li>Very intertwined, making it extremely difficult to separate them clearly. They do tend to different sides of the plot (in the x-axis), but they do have noticeable overlap.</li> </ul> </li> <li><p>Discuss the linear separability of the data. Explain why this type of data structure poses a challenge for simple linear models and would likely require a multi-layer neural network with non-linear activation functions to be classified accurately.</p> <ul> <li>Creating a single line that segregates these two classes is not possible, given that they do have overlap. If you were to trace a line between them, it would end up inevitably classifying class A as class B and vice-versa.</li> </ul> </li> </ol> </li> </ol> <p> </p> In\u00a0[16]: Copied! <pre>import pandas as pd\n\ndf = pd.read_csv(\"../../../data/SpaceshipTitanic/train.csv\")\n\ndf.head()\n</pre> import pandas as pd  df = pd.read_csv(\"../../../data/SpaceshipTitanic/train.csv\")  df.head() Out[16]: PassengerId HomePlanet CryoSleep Cabin Destination Age VIP RoomService FoodCourt ShoppingMall Spa VRDeck Name Transported 0 0001_01 Europa False B/0/P TRAPPIST-1e 39.0 False 0.0 0.0 0.0 0.0 0.0 Maham Ofracculy False 1 0002_01 Earth False F/0/S TRAPPIST-1e 24.0 False 109.0 9.0 25.0 549.0 44.0 Juanna Vines True 2 0003_01 Europa False A/0/S TRAPPIST-1e 58.0 True 43.0 3576.0 0.0 6715.0 49.0 Altark Susent False 3 0003_02 Europa False A/0/S TRAPPIST-1e 33.0 False 0.0 1283.0 371.0 3329.0 193.0 Solam Susent False 4 0004_01 Earth False F/1/S TRAPPIST-1e 16.0 False 303.0 70.0 151.0 565.0 2.0 Willy Santantines True In\u00a0[17]: Copied! <pre>null_counts = df.isnull().sum()\n\nprint(\"Null values per column:\")\nprint(null_counts) \n</pre> null_counts = df.isnull().sum()  print(\"Null values per column:\") print(null_counts)  <pre>Null values per column:\nPassengerId       0\nHomePlanet      201\nCryoSleep       217\nCabin           199\nDestination     182\nAge             179\nVIP             203\nRoomService     181\nFoodCourt       183\nShoppingMall    208\nSpa             183\nVRDeck          188\nName            200\nTransported       0\ndtype: int64\n</pre> <p>For these missing values, we must treat numerical and categorical features separately.</p> <p>For numerical features, we use a Simple Imputer to fill null values. In this instance, I chose the Median value to be used as filler. After that, we use a Standard Scaler to put all values centered at 0.</p> <p>For categorical features, we use the most frequent class as a fill-in for missing values, and pass it to a OneHotEncoder afterwards so our categorical values become boolean features. In this case, this gave us 26 features compared to our initial 14</p> In\u00a0[34]: Copied! <pre>from sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nimport pandas as pd\n\n\nX = df.drop([\"PassengerId\", \"Name\"], axis=1)\n\nprint(\"Original Data Without PassengerId and Name\")\nprint(X.shape)\n\nX[[\"Deck\", \"Num\", \"Side\"]] = X[\"Cabin\"].str.split(\"/\", expand=True)\nX.drop(\"Cabin\", axis=1, inplace=True)\n\nprint(\"\\nAfter splitting Cabin into Deck, Number and Side of ship (3 new columns)\")\nprint(X.shape)\n\nnum_features = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\ncat_features = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\", \"Deck\", \"Side\"]\n\nnum_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"scaler\", StandardScaler())\n])\n\ncat_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n])\n\npreprocessor = ColumnTransformer([\n    (\"num\", num_pipeline, num_features),\n    (\"cat\", cat_pipeline, cat_features)\n])\n\nX_processed = preprocessor.fit_transform(X)\n\nprint(\"\\nAfter Pipelines\")\nprint(X_processed.shape)\n</pre> from sklearn.preprocessing import StandardScaler, OneHotEncoder from sklearn.impute import SimpleImputer from sklearn.compose import ColumnTransformer from sklearn.pipeline import Pipeline import pandas as pd   X = df.drop([\"PassengerId\", \"Name\"], axis=1)  print(\"Original Data Without PassengerId and Name\") print(X.shape)  X[[\"Deck\", \"Num\", \"Side\"]] = X[\"Cabin\"].str.split(\"/\", expand=True) X.drop(\"Cabin\", axis=1, inplace=True)  print(\"\\nAfter splitting Cabin into Deck, Number and Side of ship (3 new columns)\") print(X.shape)  num_features = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"] cat_features = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\", \"Deck\", \"Side\"]  num_pipeline = Pipeline([     (\"imputer\", SimpleImputer(strategy=\"median\")),     (\"scaler\", StandardScaler()) ])  cat_pipeline = Pipeline([     (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),     (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")) ])  preprocessor = ColumnTransformer([     (\"num\", num_pipeline, num_features),     (\"cat\", cat_pipeline, cat_features) ])  X_processed = preprocessor.fit_transform(X)  print(\"\\nAfter Pipelines\") print(X_processed.shape) <pre>Original Data Without PassengerId and Name\n(8693, 12)\n\nAfter splitting Cabin into Deck, Number and Side of ship (3 new columns)\n(8693, 14)\n\nAfter Pipelines\n(8693, 26)\n</pre> <ol> <li>Preprocess the Data: Your goal is to clean and transform the data so it can be fed into a neural network. The <code>tanh</code> activation function produces outputs in the range <code>[-1, 1]</code>, so your input data should be scaled appropriately for stable training.<ul> <li>Handle Missing Data: Devise and implement a strategy to handle the missing values in all the affected columns. Justify your choices.</li> <li>Encode Categorical Features: Convert categorical columns like <code>HomePlanet</code>, <code>CryoSleep</code>, and <code>Destination</code> into a numerical format. One-hot encoding is a good choice.</li> <li>Normalize/Standardize Numerical Features: Scale the numerical columns (e.g., <code>Age</code>, <code>RoomService</code>, etc.). Since the <code>tanh</code> activation function is centered at zero and outputs values in <code>[-1, 1]</code>, Standardization (to mean 0, std 1) or Normalization to a <code>[-1, 1]</code> range are excellent choices. Implement one and explain why it is a good practice for training neural networks with this activation function.</li> </ul> </li> <li>Visualize the Results:<ul> <li>Create histograms for one or two numerical features (like <code>FoodCourt</code> or <code>Age</code>) before and after scaling to show the effect of your transformation.</li> </ul> </li> </ol> In\u00a0[35]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\nfig, axes = plt.subplots(len(num_features), 2, figsize=(25, 4*len(num_features)))\n\nfor i in range(len(num_features)):\n    \n    feature = num_features[i]\n    \n    df[feature].hist(ax=axes[i, 0], bins=30, color=\"skyblue\")\n    axes[i, 0].set_title(f\"{feature} before scaling\")\n\n    scaled = StandardScaler().fit_transform(df[[feature]].fillna(df[feature].median()))\n    pd.Series(scaled.ravel()).hist(ax=axes[i, 1], bins=30, color=\"salmon\")\n    axes[i, 1].set_title(f\"{feature} after standardization\")\n\nplt.tight_layout()\nplt.show()\n</pre> import numpy as np import matplotlib.pyplot as plt import pandas as pd from sklearn.preprocessing import StandardScaler  fig, axes = plt.subplots(len(num_features), 2, figsize=(25, 4*len(num_features)))  for i in range(len(num_features)):          feature = num_features[i]          df[feature].hist(ax=axes[i, 0], bins=30, color=\"skyblue\")     axes[i, 0].set_title(f\"{feature} before scaling\")      scaled = StandardScaler().fit_transform(df[[feature]].fillna(df[feature].median()))     pd.Series(scaled.ravel()).hist(ax=axes[i, 1], bins=30, color=\"salmon\")     axes[i, 1].set_title(f\"{feature} after standardization\")  plt.tight_layout() plt.show()  <p>Notice that the shape of the graphs is maintained, but the values in the x-axis are centered to 0.</p>"},{"location":"notebook1/ex1_data/#exercise-1","title":"Exercise 1\u00b6","text":""},{"location":"notebook1/ex1_data/#exploring-class-separability-in-2d","title":"Exploring Class Separability in 2D\u00b6","text":"<p>Understanding how data is distributed is the first step before designing a network architecture. In this exercise, you will generate and visualize a two-dimensional dataset to explore how data distribution affects the complexity of the decision boundaries a neural network would need to learn.</p>"},{"location":"notebook1/ex1_data/#instructions","title":"Instructions\u00b6","text":"<ol> <li>Generate the Data: Create a synthetic dataset with a total of 400 samples, divided equally among 4 classes (100 samples each). Use a Gaussian distribution to generate the points for each class based on the following parameters:<ul> <li>Class 0: Mean = [2, 3], Standard Deviation = [0.8, 2.5]</li> <li>Class 1: Mean = [5, 6], Standard Deviation = [1.2, 1.9]</li> <li>Class 2: Mean = [8, 1], Standard Deviation = [0.9, 0.9]</li> <li>Class 3: Mean = [15, 4], Standard Deviation = [0.5, 2.0]</li> </ul> </li> </ol>"},{"location":"notebook1/ex1_data/#exercise-2","title":"Exercise 2\u00b6","text":""},{"location":"notebook1/ex1_data/#non-linearity-in-higher-dimensions","title":"Non-Linearity in Higher Dimensions\u00b6","text":"<p>Simple neural networks (like a Perceptron) can only learn linear boundaries. Deep networks excel when data is not linearly separable. This exercise challenges you to create and visualize such a dataset.</p>"},{"location":"notebook1/ex1_data/#instructions","title":"Instructions\u00b6","text":"<ol> <li><p>Generate the Data: Create a dataset with 500 samples for Class A and 500 samples for Class B. Use a multivariate normal distribution with the following parameters:</p> <ul> <li><p>Class A:</p> <p>Mean vector:</p> <p>$$\\mu_A = [0, 0, 0, 0, 0]$$</p> <p>Covariance matrix:</p> <p>$$   \\Sigma_A = \\begin{pmatrix}   1.0 &amp; 0.8 &amp; 0.1 &amp; 0.0 &amp; 0.0 \\\\   0.8 &amp; 1.0 &amp; 0.3 &amp; 0.0 &amp; 0.0 \\\\   0.1 &amp; 0.3 &amp; 1.0 &amp; 0.5 &amp; 0.0 \\\\   0.0 &amp; 0.0 &amp; 0.5 &amp; 1.0 &amp; 0.2 \\\\   0.0 &amp; 0.0 &amp; 0.0 &amp; 0.2 &amp; 1.0   \\end{pmatrix}   $$</p> </li> <li><p>Class B:</p> <p>Mean vector:</p> <p>$$\\mu_B = [1.5, 1.5, 1.5, 1.5, 1.5]$$</p> <p>Covariance matrix:</p> <p>$$   \\Sigma_B = \\begin{pmatrix}   1.5 &amp; -0.7 &amp; 0.2 &amp; 0.0 &amp; 0.0 \\\\   -0.7 &amp; 1.5 &amp; 0.4 &amp; 0.0 &amp; 0.0 \\\\   0.2 &amp; 0.4 &amp; 1.5 &amp; 0.6 &amp; 0.0 \\\\   0.0 &amp; 0.0 &amp; 0.6 &amp; 1.5 &amp; 0.3 \\\\   0.0 &amp; 0.0 &amp; 0.0 &amp; 0.3 &amp; 1.5   \\end{pmatrix}   $$</p> </li> </ul> </li> </ol>"},{"location":"notebook1/ex1_data/#exercise-3","title":"Exercise 3\u00b6","text":""},{"location":"notebook1/ex1_data/#preparing-real-world-data-for-a-neural-network","title":"Preparing Real-World Data for a Neural Network\u00b6","text":"<p>This exercise uses a real dataset from Kaggle. Your task is to perform the necessary preprocessing to make it suitable for a neural network that uses the hyperbolic tangent (<code>tanh</code>) activation function in its hidden layers.</p>"},{"location":"notebook1/ex1_data/#instructions","title":"Instructions\u00b6","text":"<ol> <li><p>Get the Data: Download the Spaceship Titanic dataset from Kaggle.</p> </li> <li><p>Describe the Data:</p> <ul> <li><p>Briefly describe the dataset's objective (i.e., what does the <code>Transported</code> column represent?).</p> <ul> <li>We're trying to predict if a passenger was transported to another dimension during the crash of the Spaceship Titanic, the value that represents whether or not the passenger was transported is in the <code>Transported column</code></li> </ul> </li> <li><p>List the features and identify which are numerical (e.g., <code>Age</code>, <code>RoomService</code>) and which are categorical (e.g., <code>HomePlanet</code>, <code>Destination</code>).</p> </li> <li><p>Investigate the dataset for missing values. Which columns have them, and how many?</p> </li> </ul> </li> </ol> <p>Categorical Columns -</p> <ul> <li>HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.</li> <li>Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.</li> <li>Destination - The planet the passenger will be debarking to.</li> <li>Name - The first and last names of the passenger.</li> <li>PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.</li> </ul> <p>Boolean Columns -</p> <ul> <li>Transported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.</li> <li>VIP - Whether the passenger has paid for special VIP service during the voyage.</li> <li>CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.</li> </ul> <p>Numerical Columns -</p> <ul> <li>Age - The age of the passenger.</li> <li>RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.</li> </ul>"},{"location":"projeto/main/","title":"Projeto","text":"<p>Aqui vai toda a documenta\u00e7\u00e3o do projeto, incluindo o que j\u00e1 foi feito e o que falta fazer.</p>"},{"location":"roteiro1/main/","title":"Roteiro 1","text":""},{"location":"roteiro1/main/#objetivo","title":"Objetivo","text":"<p>Aqui vai o objetivo macro do roteiro. Por que estamos fazendo o que estamos fazendo?</p>"},{"location":"roteiro1/main/#montagem-do-roteiro","title":"Montagem do Roteiro","text":"<p>Os pontos \"tarefas\" s\u00e3o os passos que devem ser seguidos para a realiza\u00e7\u00e3o do roteiro. Eles devem ser claros e objetivos. Com evid\u00eancias claras de que foram realizados.</p>"},{"location":"roteiro1/main/#tarefa-1","title":"Tarefa 1","text":"<p>Instalando o MAAS:</p> sudo snap install maas --channel=3.5/Stable <p></p> <p>Dashboard do MAAS</p> <p>Conforme ilustrado acima, a tela inicial do MAAS apresenta um dashboard com informa\u00e7\u00f5es sobre o estado atual dos servidores gerenciados. O dashboard \u00e9 composto por diversos pain\u00e9is, cada um exibindo informa\u00e7\u00f5es sobre um aspecto espec\u00edfico do ambiente gerenciado. Os pain\u00e9is podem ser configurados e personalizados de acordo com as necessidades do usu\u00e1rio.</p>"},{"location":"roteiro1/main/#tarefa-2","title":"Tarefa 2","text":""},{"location":"roteiro1/main/#app","title":"App","text":""},{"location":"roteiro1/main/#tarefa-1_1","title":"Tarefa 1","text":""},{"location":"roteiro1/main/#tarefa-2_1","title":"Tarefa 2","text":"<p>Exemplo de diagrama</p> <pre><code>architecture-beta\n    group api(cloud)[API]\n\n    service db(database)[Database] in api\n    service disk1(disk)[Storage] in api\n    service disk2(disk)[Storage] in api\n    service server(server)[Server] in api\n\n    db:L -- R:server\n    disk1:T -- B:server\n    disk2:T -- B:db</code></pre> <p>Mermaid</p>"},{"location":"roteiro1/main/#questionario-projeto-ou-plano","title":"Question\u00e1rio, Projeto ou Plano","text":"<p>Esse se\u00e7\u00e3o deve ser preenchida apenas se houver demanda do roteiro.</p>"},{"location":"roteiro1/main/#discussoes","title":"Discuss\u00f5es","text":"<p>Quais as dificuldades encontradas? O que foi mais f\u00e1cil? O que foi mais dif\u00edcil?</p>"},{"location":"roteiro1/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O que foi poss\u00edvel concluir com a realiza\u00e7\u00e3o do roteiro?</p>"},{"location":"roteiro2/main/","title":"Roteiro 2","text":""},{"location":"roteiro2/main/#diagrama-de-classes-do-banco","title":"Diagrama de Classes do Banco","text":"<pre><code>classDiagram\n    class Conta {\n        - String id\n        # double saldo\n        - Cliente cliente\n        + sacar(double valor)\n        + depositar(double valor)\n    }\n    class Cliente {\n        - String id\n        - String nome\n        - List&lt;Conta&gt; contas\n    }\n    class PessoaFisica {\n        - String cpf\n    }\n    class PessoaJuridica {\n        - String cnpj\n    }\n    class ContaCorrente {\n        - double limite\n        + sacar(double valor)\n    }\n    class ContaPoupanca {\n        + sacar(double valor)\n    }\n    Conta *-- Cliente\n    Conta &lt;|-- ContaCorrente\n    Conta &lt;|-- ContaPoupanca\n    Cliente &lt;|-- PessoaFisica\n    Cliente &lt;|-- PessoaJuridica</code></pre>"},{"location":"roteiro2/main/#diagrama-de-sequencia-de-autorizacao","title":"Diagrama de Seq\u00fc\u00eancia de Autoriza\u00e7\u00e3o","text":"<pre><code>sequenceDiagram\n  autonumber\n  actor User\n  User-&gt;&gt;Auth Service: request with token\n  Auth Service-&gt;&gt;Auth Service: decodes the token and extracts claims\n  Auth Service-&gt;&gt;Auth Service: verifies permissions\n  critical allowed\n    Auth Service-&gt;&gt;Secured Resource: authorizes the request\n    Secured Resource-&gt;&gt;User: returns the response\n  option denied\n    Auth Service--&gt;&gt;User: unauthorized message\n  end  </code></pre>"},{"location":"roteiro3/main/","title":"Roteiro 3","text":"<p>Running the code below in Browser (Woooooowwwwww!!!!!!). <sup>1</sup></p> <p> </p> Editor (session: default) Run <pre>import ssl\nimport pandas as pd\n\ndf = pd.DataFrame()\ndf['AAPL'] = pd.Series([1, 2, 3])\ndf['MSFT'] = pd.Series([4, 5, 6])\ndf['GOOGL'] = pd.Series([7, 8, 9])\n\nprint(df)\n</pre> Output Clear <pre></pre> <p></p> <ol> <li> <p>Pyodide \u21a9</p> </li> </ol>"},{"location":"roteiro4/limit.def/","title":"Limit.def","text":"In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nfrom io import StringIO\n</pre> import matplotlib.pyplot as plt import numpy as np from io import StringIO In\u00a0[\u00a0]: Copied! <pre>eq = lambda x: np.exp(x)\n</pre> eq = lambda x: np.exp(x) In\u00a0[\u00a0]: Copied! <pre>x = np.linspace(-.2, 2.1)\n</pre> x = np.linspace(-.2, 2.1) In\u00a0[\u00a0]: Copied! <pre>plt.rcParams[\"figure.figsize\"] = (15, 5)\n</pre> plt.rcParams[\"figure.figsize\"] = (15, 5) In\u00a0[\u00a0]: Copied! <pre>xa = 1.5\nya = 7\nk = 0.3\nka = xa - k\nak = xa + k\n</pre> xa = 1.5 ya = 7 k = 0.3 ka = xa - k ak = xa + k In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(1, 3)\nfor i in range(3):\n  ax[i].axhline(0, color='gray') # x = 0\n  ax[i].axvline(0, color='gray') # y = 0\n  ax[i].spines['top'].set_visible(False)\n  ax[i].spines['right'].set_visible(False)\n  ax[i].spines['bottom'].set_visible(False)\n  ax[i].spines['left'].set_visible(False)\n  ax[i].plot(x, eq(x), '-r', lw=4)\n  ax[i].set_xlim(min(x), max(x))\n  ax[i].set_xticks([])\n  ax[i].set_yticks([])\n  ax[i].plot([ka, ka], [0, eq(ka)], 'g:')\n  ax[i].plot([0, ka], [eq(ka), eq(ka)], 'g:')\n  ax[i].plot([ak, ak], [0, eq(ak)], 'g:')\n  ax[i].plot([0, ak], [eq(ak), eq(ak)], 'g:')\n  ax[i].text(xa, -0.5, 'a', horizontalalignment='center', fontsize=15)\n  ax[i].text(ka, -0.5, '$a-\\delta$', horizontalalignment='center', fontsize=15)\n  ax[i].text(ak, -0.5, '$a+\\delta$', horizontalalignment='center', fontsize=15)\n  ax[i].text(0, eq(ka), '$L-\\epsilon$', horizontalalignment='right', verticalalignment='center', fontsize=15)\n  ax[i].text(0, eq(ak), '$L+\\epsilon$', horizontalalignment='right', verticalalignment='center', fontsize=15)\n</pre> fig, ax = plt.subplots(1, 3) for i in range(3):   ax[i].axhline(0, color='gray') # x = 0   ax[i].axvline(0, color='gray') # y = 0   ax[i].spines['top'].set_visible(False)   ax[i].spines['right'].set_visible(False)   ax[i].spines['bottom'].set_visible(False)   ax[i].spines['left'].set_visible(False)   ax[i].plot(x, eq(x), '-r', lw=4)   ax[i].set_xlim(min(x), max(x))   ax[i].set_xticks([])   ax[i].set_yticks([])   ax[i].plot([ka, ka], [0, eq(ka)], 'g:')   ax[i].plot([0, ka], [eq(ka), eq(ka)], 'g:')   ax[i].plot([ak, ak], [0, eq(ak)], 'g:')   ax[i].plot([0, ak], [eq(ak), eq(ak)], 'g:')   ax[i].text(xa, -0.5, 'a', horizontalalignment='center', fontsize=15)   ax[i].text(ka, -0.5, '$a-\\delta$', horizontalalignment='center', fontsize=15)   ax[i].text(ak, -0.5, '$a+\\delta$', horizontalalignment='center', fontsize=15)   ax[i].text(0, eq(ka), '$L-\\epsilon$', horizontalalignment='right', verticalalignment='center', fontsize=15)   ax[i].text(0, eq(ak), '$L+\\epsilon$', horizontalalignment='right', verticalalignment='center', fontsize=15) In\u00a0[\u00a0]: Copied! <pre>ax[0].plot([xa, xa], [0, eq(xa)], 'b:')\nax[0].plot([0, xa], [eq(xa), eq(xa)], 'b:')\nax[0].plot(xa, eq(xa), 'ro', ms=15)\nax[0].text(0, eq(xa), 'L=f(a)', horizontalalignment='right', verticalalignment='center', fontsize=15)\nax[1].plot([xa, xa], [0, eq(xa)], 'b:')\nax[1].plot([0, xa], [eq(xa), eq(xa)], 'm:')\nax[1].plot(xa, eq(xa), marker='o', ms=15, mec='red', color='white')\nax[1].text(0, eq(xa), 'L', horizontalalignment='right', verticalalignment='center', fontsize=15)\nax[2].plot(xa, eq(xa), marker='o', ms=15, mec='white', color='white')\nax[2].plot([xa, xa], [0, ya], 'b:')\nax[2].plot([0, xa], [ya, ya], 'b:')\nax[2].plot([0, xa], [eq(xa), eq(xa)], 'm:')\nax[2].plot(xa, eq(xa), marker='o', ms=15, mec='red', color='white')\nax[2].plot(xa, ya, 'ro', ms=15)\nax[2].text(0, ya, 'f(a)', horizontalalignment='right', verticalalignment='center', fontsize=15)\nax[2].text(0, eq(xa), 'L', horizontalalignment='right', verticalalignment='center', fontsize=15)\n</pre> ax[0].plot([xa, xa], [0, eq(xa)], 'b:') ax[0].plot([0, xa], [eq(xa), eq(xa)], 'b:') ax[0].plot(xa, eq(xa), 'ro', ms=15) ax[0].text(0, eq(xa), 'L=f(a)', horizontalalignment='right', verticalalignment='center', fontsize=15) ax[1].plot([xa, xa], [0, eq(xa)], 'b:') ax[1].plot([0, xa], [eq(xa), eq(xa)], 'm:') ax[1].plot(xa, eq(xa), marker='o', ms=15, mec='red', color='white') ax[1].text(0, eq(xa), 'L', horizontalalignment='right', verticalalignment='center', fontsize=15) ax[2].plot(xa, eq(xa), marker='o', ms=15, mec='white', color='white') ax[2].plot([xa, xa], [0, ya], 'b:') ax[2].plot([0, xa], [ya, ya], 'b:') ax[2].plot([0, xa], [eq(xa), eq(xa)], 'm:') ax[2].plot(xa, eq(xa), marker='o', ms=15, mec='red', color='white') ax[2].plot(xa, ya, 'ro', ms=15) ax[2].text(0, ya, 'f(a)', horizontalalignment='right', verticalalignment='center', fontsize=15) ax[2].text(0, eq(xa), 'L', horizontalalignment='right', verticalalignment='center', fontsize=15) In\u00a0[\u00a0]: Copied! <pre>fig.tight_layout()\n</pre> fig.tight_layout() In\u00a0[\u00a0]: Copied! <pre>buffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n</pre> buffer = StringIO() plt.savefig(buffer, format=\"svg\", transparent=True) print(buffer.getvalue())"},{"location":"roteiro4/main/","title":"Roteiro 4","text":"<p>Se chegou aqui, \u00e9 porque voc\u00ea est\u00e1 interessado em saber mais. Logo, de brinde, como rodar um c\u00f3digo <code>Python</code> aqui.</p> 2025-09-19T16:42:51.216208 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ 2025-09-19T16:42:52.355410 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <p>Markdown-exec \u00e9 uma extens\u00e3o do Markdown que permite executar c\u00f3digo Python diretamente no Markdown. Isso \u00e9 \u00fatil para gerar resultados din\u00e2micos ou executar scripts de forma interativa.</p>"},{"location":"roteiro4/smc/","title":"Smc","text":"In\u00a0[\u00a0]: Copied! <pre>from datetime import datetime\nimport matplotlib.pyplot as plt\nimport yfinance as yf\nimport numpy as np\nimport pandas as pd\nfrom io import StringIO\n</pre> from datetime import datetime import matplotlib.pyplot as plt import yfinance as yf import numpy as np import pandas as pd from io import StringIO In\u00a0[\u00a0]: Copied! <pre>num_days = 250\nnum_simulations = 200\norder_poly = 1\n</pre> num_days = 250 num_simulations = 200 order_poly = 1 In\u00a0[\u00a0]: Copied! <pre>ticker = '^BVSP'\n</pre> ticker = '^BVSP' In\u00a0[\u00a0]: Copied! <pre>info = yf.Ticker(ticker)\ndata = info.history(period='2y')\n</pre> info = yf.Ticker(ticker) data = info.history(period='2y') In\u00a0[\u00a0]: Copied! <pre>close = data['Close']\ndaily_return = close.pct_change()\n</pre> close = data['Close'] daily_return = close.pct_change() In\u00a0[\u00a0]: Copied! <pre>x = np.linspace(1, len(close), len(close))\nf = np.poly1d(np.polyfit(x, close, order_poly))\nxs = np.linspace(max(x), max(x) + num_days, num_days)\n</pre> x = np.linspace(1, len(close), len(close)) f = np.poly1d(np.polyfit(x, close, order_poly)) xs = np.linspace(max(x), max(x) + num_days, num_days) In\u00a0[\u00a0]: Copied! <pre>sigma = daily_return.std()\nmu = daily_return.mean()\n</pre> sigma = daily_return.std() mu = daily_return.mean() In\u00a0[\u00a0]: Copied! <pre>simulated_prices = np.zeros((num_days, num_simulations))\n</pre> simulated_prices = np.zeros((num_days, num_simulations)) In\u00a0[\u00a0]: Copied! <pre>for i in range(num_simulations):\n    simulated_prices[0][i] = close[-1]\n    for j in range(1, num_days):\n        daily_return = np.random.normal(mu, sigma)\n        simulated_prices[j][i] = simulated_prices[j-1][i] * (1 + daily_return)\n</pre> for i in range(num_simulations):     simulated_prices[0][i] = close[-1]     for j in range(1, num_days):         daily_return = np.random.normal(mu, sigma)         simulated_prices[j][i] = simulated_prices[j-1][i] * (1 + daily_return) In\u00a0[\u00a0]: Copied! <pre>simulated_means = np.mean(simulated_prices, axis=1)\nsimulated_stds = np.std(simulated_prices, axis=1)\n</pre> simulated_means = np.mean(simulated_prices, axis=1) simulated_stds = np.std(simulated_prices, axis=1) In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(1, 1, figsize=(12, 8))\nax.plot(\n    x, close,\n    x, f(x), 'r:',\n    xs, simulated_prices,\n    xs, simulated_means,\n    xs, simulated_means + 1*simulated_stds, 'w:',\n    xs, simulated_means - 1*simulated_stds, 'w:',\n    xs, simulated_means + 2*simulated_stds, 'k:',\n    xs, simulated_means - 2*simulated_stds, 'k:',\n    xs, f(xs), 'g',\n)\nax.set_xlim(min(x), max(xs))\n</pre> fig, ax = plt.subplots(1, 1, figsize=(12, 8)) ax.plot(     x, close,     x, f(x), 'r:',     xs, simulated_prices,     xs, simulated_means,     xs, simulated_means + 1*simulated_stds, 'w:',     xs, simulated_means - 1*simulated_stds, 'w:',     xs, simulated_means + 2*simulated_stds, 'k:',     xs, simulated_means - 2*simulated_stds, 'k:',     xs, f(xs), 'g', ) ax.set_xlim(min(x), max(xs)) In\u00a0[\u00a0]: Copied! <pre>buffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</pre> buffer = StringIO() plt.savefig(buffer, format=\"svg\") print(buffer.getvalue())"},{"location":"thisdocumentation/main/","title":"This documentation","text":""},{"location":"thisdocumentation/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que voc\u00ea possui os seguintes pr\u00e9-requisitos instalados em seu sistema:</p> <ul> <li>Git: Para clonar o reposit\u00f3rio.</li> </ul>"},{"location":"thisdocumentation/main/#instalando-o-python","title":"Instalando o Python","text":"LinuxmacOSWindows <p>Instale o Python 3.8 ou superior.</p> <pre><code>sudo apt install python3 python3-venv python3-pip\npython3 --version\n</code></pre> <p>Instale o Python 3.8 ou superior.</p> <pre><code>brew install python\npython3 --version\n</code></pre> <p>Instale o Python 3.13 ou superior. Baixe o instalador do site oficial do Python (https://www.python.org/downloads/) e execute-o. Certifique-se de marcar a op\u00e7\u00e3o \"Add Python to PATH\" durante a instala\u00e7\u00e3o.</p> <pre><code>python --version\n</code></pre>"},{"location":"thisdocumentation/main/#usage","title":"Usage","text":"<p>Para utilizar o c\u00f3digo deste reposit\u00f3rio, siga as instru\u00e7\u00f5es a seguir:</p> <p>Clone ou fork este reposit\u00f3rio:</p> <pre><code>git clone &lt;URL_DO_REPOSITORIO&gt;\n</code></pre> <p>Crie um ambiente virtual do Python:</p> Linux/macOSWindows <pre><code>python3 -m venv env\n</code></pre> <pre><code>python -m venv env\n</code></pre> <p>Ative o ambiente virtual (voc\u00ea deve fazer isso sempre que for executar algum script deste reposit\u00f3rio):</p> Linux/macOSWindows <pre><code>source ./env/bin/activate\n</code></pre> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Instale as depend\u00eancias com:</p> Linux/macOSWindows <pre><code>python3 -m pip install -r requirements.txt --upgrade\n</code></pre> <pre><code>python -m pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"thisdocumentation/main/#deployment","title":"Deployment","text":"<p>O material utiliza o mkdocs para gerar a documenta\u00e7\u00e3o. Para visualizar a documenta\u00e7\u00e3o, execute o comando:</p> <pre><code>mkdocs serve -o\n</code></pre> <p>Para subir ao GitHub Pages, execute o comando:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>Esse reposit\u00f3rio possui um workflow do GitHub Actions que executa o comando <code>mkdocs gh-deploy</code> sempre que houver um push na branch <code>main</code>. Assim, n\u00e3o \u00e9 necess\u00e1rio executar esse comando manualmente. Toda vez que voc\u00ea fizer um push na branch <code>main</code>, a documenta\u00e7\u00e3o ser\u00e1 atualizada automaticamente no GitHub Pages.</p> <p>Aviso 1</p> <p>Para que o github actions funcione corretamente, \u00e9 necess\u00e1rio que o reposit\u00f3rio esteja configurado para que o bot <code>github-actions[bot]</code> tenha permiss\u00e3o de escrita. Voc\u00ea pode verificar isso nas configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Actions\" e depois em \"General\". Certifique-se de que a op\u00e7\u00e3o \"Workflow permissions\" esteja definida como \"Read and write permissions\".</p> <p></p> <p>Aviso 2</p> <p>Depois de publicar, caso n\u00e3o consiga acessar a p\u00e1gina, verifique se o github pages est\u00e1 configurado corretamente. V\u00e1 at\u00e9 as configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Pages\" e verifique se a branch <code>gh-pages</code> est\u00e1 selecionada como fonte. Se n\u00e3o estiver, selecione-a e salve as altera\u00e7\u00f5es.</p> <p></p> <p>Pay Attention</p> <p>No arquivo '<code>mkdocs.yml</code>, a se\u00e7\u00e3o <code>site_url</code> deve estar configurada corretamente para o seu reposit\u00f3rio. Por exemplo, se o seu reposit\u00f3rio estiver em <code>https://github.com/usuario/repositorio</code>, a se\u00e7\u00e3o <code>site_url</code> deve ser:</p> <pre><code>site_url: https://usuario.github.io/repositorio\n</code></pre> <p>Tamb\u00e9m, certifique-se de que a se\u00e7\u00e3o <code>repo_url</code> esteja configurada corretamente para o seu reposit\u00f3rio. Por exemplo:</p> <pre><code>repo_url: https://github.com/usuario/repositorio\n</code></pre>"}]}